# AI Conflict Dashboard - Environment Configuration
# Copy this file to .env and add your API keys

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude Configuration
# Get your API key from: https://console.anthropic.com/account/keys
CLAUDE_API_KEY=your_claude_api_key_here

# Google Gemini Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# xAI Grok Configuration
# Get your API key from: https://console.x.ai/
GROK_API_KEY=your_grok_api_key_here

# Application Settings
# Port for the backend API server
API_PORT=8000

# Frontend development server port
FRONTEND_PORT=3000

# Enable debug mode (true/false)
DEBUG=false

# Ollama Configuration (for local LLMs)
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Database Configuration
# SQLite database path (relative to app root)
DATABASE_PATH=./data/app.db

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# CORS Configuration (comma-separated origins)
# For development, you can use * but specify origins in production
ALLOWED_ORIGINS=tauri://localhost,http://localhost:3000

# Rate Limiting (requests per minute)
RATE_LIMIT=60

# Timeout Settings (in seconds)
API_TIMEOUT=30