# Shared Code Strategy

This desktop app maximizes code reuse from the existing web application.

## Architecture

```
ai-conflict-dashboard/
â”œâ”€â”€ backend/                    # Original web backend (shared)
â”‚   â”œâ”€â”€ llm_providers.py       # âœ… Reused for AI calls
â”‚   â”œâ”€â”€ token_utils.py         # âœ… Reused for token counting
â”‚   â”œâ”€â”€ smart_chunking.py      # âœ… Reused for text processing
â”‚   â”œâ”€â”€ structured_logging.py  # âœ… Reused for logging
â”‚   â””â”€â”€ plugins/               # âœ… Reused (Ollama support)
â”‚
â””â”€â”€ desktop-app/
    â”œâ”€â”€ backend/
    â”‚   â””â”€â”€ desktop_main.py    # Imports & extends web backend
    â””â”€â”€ src/                   # New React frontend

```

## How It Works

1. **desktop_main.py** adds the parent backend to Python path
2. Imports all the battle-tested functions from web backend
3. Wraps them in desktop-specific API endpoints
4. Adds Tauri-specific CORS configuration

## Benefits

- **No Code Duplication**: All LLM logic stays in one place
- **Bug Fixes Apply Everywhere**: Fix once, both apps benefit
- **Consistent Behavior**: Same AI processing in web & desktop
- **Easier Maintenance**: Single source of truth

## What's Shared

### âœ… Fully Reused
- All LLM provider integrations (OpenAI, Claude, Gemini, Grok, Ollama)
- Token counting and text chunking
- Smart chunking (preserves code blocks)
- Circuit breakers and error handling
- Structured logging

### ðŸ”„ Adapted for Desktop
- CORS configuration (added `tauri://localhost`)
- API endpoints (simplified for desktop use)
- Environment variables (desktop-specific .env)

### ðŸ†• Desktop-Specific
- SQLite integration (coming in Task 1.2)
- Tauri IPC commands
- Local file system access
- Desktop-specific UI (React instead of vanilla JS)

## Future Considerations

When adding new features:
1. Add to `backend/` if it's AI/processing logic
2. Add to `desktop-app/backend/` if it's desktop-specific
3. Keep the separation clean for maximum reuse