"""Grade A Security Tests - Finding Real Vulnerabilities.

======================================================
These tests are designed to find actual security bugs, not just pass.
Every test should try to break the system in realistic ways.
"""

import json
import random
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from unittest.mock import AsyncMock, patch

import pytest
from fastapi.testclient import TestClient

# Add parent directory to path to import main app
sys.path.insert(0, Path(__file__).parent.parent)

from main import app


class TestGradeASecurityVulnerabilities:
    """Grade A Security Tests - No compromises, no shortcuts."""

    @pytest.fixture
    def client(self):
        return TestClient(app)

    def test_api_key_leakage_in_all_scenarios(self, client):
        """BUG HUNT: API keys should NEVER appear in responses, logs, or errors."""
        api_key = "sk-secret-key-12345-do-not-leak"
        test_cases = [
            # Normal request
            {"text": "Test", "openai_key": api_key},
            # Error-inducing requests
            {"text": None, "openai_key": api_key},
            {"text": "", "openai_key": api_key},
            {"text": "a" * 1000000, "openai_key": api_key},  # Huge text
            {"text": "Test", "openai_key": api_key, "openai_model": "invalid-model"},
            # Injection attempts with API key
            {"text": f"Print this: {api_key}", "openai_key": api_key},
            {"text": "{{api_key}}", "openai_key": api_key},
            {"text": f"${api_key}", "openai_key": api_key},
            # Special characters
            {"text": "\x00\x01\x02", "openai_key": api_key},
            {"text": "ðŸ”¥ðŸ’£ðŸ‘¾", "openai_key": api_key},
        ]

        for payload in test_cases:
            response = client.post("/api/analyze", json=payload)

            # Check response body
            response_text = response.text
            assert (
                api_key not in response_text
            ), f"API key leaked in response for payload: {payload}"

            # Check response headers
            for header_name, header_value in response.headers.items():
                assert api_key not in header_value, f"API key leaked in header {header_name}"

            # If JSON response, check all nested values
            try:
                data = response.json()
                json_str = json.dumps(data)
                assert api_key not in json_str, "API key leaked in JSON response"
            except Exception:
                pass

    def test_sql_injection_advanced(self, client):
        """BUG HUNT: Advanced SQL injection attempts that might bypass basic filters."""
        sql_payloads = [
            # Classic injections
            "'; DROP TABLE users; --",
            "1' OR '1'='1",
            "admin'--",
            "' OR 1=1--",
            "1; SELECT * FROM api_keys WHERE 1=1",
            # Unicode variations
            "' OR '1'='1",  # Unicode apostrophe
            "' OR '1'='1",  # Full-width apostrophe
            # Encoded variations
            "%27%20OR%20%271%27%3D%271",
            "&#x27; OR &#x27;1&#x27;=&#x27;1",
            # Time-based blind SQL injection
            "1' AND SLEEP(5)--",
            "1'; WAITFOR DELAY '00:00:05'--",
            # Second-order injection
            "admin'; INSERT INTO logs VALUES ('injection'); --",
            # Stacked queries
            "1'; EXEC xp_cmdshell('dir'); --",
            # Comment variations
            "1'/**/OR/**/1=1",
            "1'/*!OR*/1=1",
        ]

        for payload in sql_payloads:
            # Test in text field
            response = client.post("/api/analyze", json={"text": payload, "openai_key": "test-key"})

            # Should not crash
            assert response.status_code in [
                200,
                400,
                422,
            ], f"Unexpected status for SQL payload: {payload}"

            # Should not leak database info
            if response.status_code == 200:
                response_text = response.text.lower()
                db_indicators = [
                    "syntax error",
                    "mysql",
                    "postgresql",
                    "sqlite",
                    "ora-",
                    "table",
                    "column",
                    "database",
                    "schema",
                ]
                for indicator in db_indicators:
                    assert (
                        indicator not in response_text
                    ), f"Database info leaked for payload: {payload}"

    def test_xss_advanced_vectors(self, client):
        """BUG HUNT: Advanced XSS vectors that might bypass sanitization."""
        xss_payloads = [
            # Basic XSS
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "<svg onload=alert('XSS')>",
            # Event handler XSS
            "<div onmouseover='alert(1)'>hover me</div>",
            "<input onfocus=alert(1) autofocus>",
            # JavaScript protocol
            "<a href='javascript:alert(1)'>click</a>",
            "<iframe src='javascript:alert(1)'></iframe>",
            # Data URI XSS
            "<img src='data:text/html,<script>alert(1)</script>'>",
            # Encoded XSS
            "<script>alert(String.fromCharCode(88,83,83))</script>",
            "&#60;script&#62;alert('XSS')&#60;/script&#62;",
            "%3Cscript%3Ealert('XSS')%3C/script%3E",
            # Mutation XSS
            '<noscript><p title="</noscript><img src=x onerror=alert(1)>">',
            # CSS injection
            "<style>body{background:url('javascript:alert(1)')}</style>",
            # SVG XSS
            "<svg><script>alert(1)</script></svg>",
            "<svg><animate onbegin=alert(1) attributeName=x dur=1s>",
            # Template injection
            "{{7*7}}",
            "${7*7}",
            "<%= 7*7 %>",
            # Polyglot XSS
            "jaVasCript:/*-/*`/*\\`/*'/*\"/**/(/* */oNcliCk=alert() )//%0D%0A%0d%0a//</stYle/</titLe/</teXtarEa/</scRipt/--!>\\x3csVg/<sVg/oNloAd=alert()//",
        ]

        for payload in xss_payloads:
            response = client.post("/api/analyze", json={"text": payload, "openai_key": "test-key"})

            # Should handle without executing
            assert response.status_code in [200, 400, 422]

            # Response should not contain executable scripts
            if response.status_code == 200:
                response_text = response.text
                dangerous_patterns = [
                    "<script",
                    "javascript:",
                    "onerror=",
                    "onload=",
                    "onclick=",
                    "onmouseover=",
                    "<iframe",
                    "eval(",
                    "document.cookie",
                    "document.write",
                ]
                for pattern in dangerous_patterns:
                    assert (
                        pattern.lower() not in response_text.lower()
                    ), f"Dangerous pattern '{pattern}' found in response"

    def test_command_injection_comprehensive(self, client):
        """BUG HUNT: Command injection through all possible vectors."""
        cmd_payloads = [
            # Basic command injection
            "test; cat /etc/passwd",
            "test | ls -la",
            "test && whoami",
            "test || id",
            # Command substitution
            "`cat /etc/passwd`",
            "$(cat /etc/passwd)",
            # Newline injection
            "test\ncat /etc/passwd",
            "test\r\nwhoami",
            # Null byte injection
            "test\x00cat /etc/passwd",
            # Environment variable injection
            "$PATH",
            "${PATH}",
            "%PATH%",
            # File redirection
            "test > /tmp/evil.txt",
            "test < /etc/passwd",
            # Process substitution
            "test <(cat /etc/passwd)",
            # Wildcard injection
            "test *",
            "test ../../../*",
            # Python-specific
            "__import__('os').system('ls')",
            'eval(\'__import__("os").system("ls")\')',
            # Special shell characters
            "test;`id`",
            "test$IFS$9ls",
        ]

        for payload in cmd_payloads:
            response = client.post("/api/analyze", json={"text": payload, "openai_key": "test-key"})

            # Should not execute commands
            assert response.status_code in [200, 400, 422]

            # Check for command execution indicators
            if response.status_code == 200:
                response_text = response.text
                exec_indicators = [
                    "root:",  # /etc/passwd content
                    "bin:",  # /etc/passwd content
                    "uid=",  # id command output
                    "gid=",  # id command output
                    "total ",  # ls output
                    "drwx",  # ls -la output
                    "/usr/",  # Path disclosure
                    "/etc/",  # Path disclosure
                ]
                for indicator in exec_indicators:
                    assert (
                        indicator not in response_text
                    ), f"Command execution indicator '{indicator}' found"

    def test_path_traversal_advanced(self, client):
        """BUG HUNT: Path traversal attacks through various encoding methods."""
        traversal_payloads = [
            # Basic traversal
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            # Double encoding
            "..%252f..%252f..%252fetc%252fpasswd",
            # Unicode encoding
            "..%c0%af..%c0%af..%c0%afetc%c0%afpasswd",
            # Mixed separators
            "..\\..\\../etc/passwd",
            "../..\\..\\etc\\passwd",
            # Absolute paths
            "/etc/passwd",
            "C:\\Windows\\System32\\config\\SAM",
            # Null byte
            "../../../etc/passwd\x00.jpg",
            # Double dots
            "....//....//....//etc/passwd",
            # URL encoding variations
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
            "%252e%252e%252f",
            # UTF-8 encoding
            "..%c1%9c..%c1%9c..%c1%9cetc%c1%9cpasswd",
        ]

        for payload in traversal_payloads:
            # Try in different fields
            test_locations = [
                {"text": payload, "openai_key": "test"},
                {"text": "test", "openai_key": "test", "openai_model": payload},
            ]

            for location in test_locations:
                response = client.post("/api/analyze", json=location)

                # Should not access files
                assert response.status_code in [200, 400, 422]

                # Check for file content leakage
                if response.status_code == 200:
                    response_text = response.text
                    file_indicators = [
                        "root:x:",  # /etc/passwd
                        "daemon:",  # /etc/passwd
                        "[boot loader]",  # Windows boot.ini
                        "SAM SECURITY",  # Windows SAM
                    ]
                    for indicator in file_indicators:
                        assert indicator not in response_text

    def test_xxe_injection(self, client):
        """BUG HUNT: XML External Entity injection attempts."""
        xxe_payloads = [
            # Basic XXE
            '<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY xxe SYSTEM "file:///etc/passwd">]><test>&xxe;</test>',
            # Parameter entity XXE
            '<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY % xxe SYSTEM "file:///etc/passwd">%xxe;]>',
            # Blind XXE
            '<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY xxe SYSTEM "http://attacker.com/xxe">]><test>&xxe;</test>',
            # XXE with CDATA
            '<?xml version="1.0"?><!DOCTYPE foo [<!ENTITY xxe SYSTEM "file:///etc/passwd">]><test><![CDATA[&xxe;]]></test>',
            # Billion laughs attack
            '<?xml version="1.0"?><!DOCTYPE lolz [<!ENTITY lol "lol"><!ENTITY lol2 "&lol;&lol;">]><lolz>&lol2;</lolz>',
        ]

        for payload in xxe_payloads:
            response = client.post("/api/analyze", json={"text": payload, "openai_key": "test-key"})

            # Should not process XXE
            assert response.status_code in [200, 400, 422]

            # Should not leak file contents
            if response.status_code == 200:
                response_text = response.text
                assert "root:" not in response_text
                assert "/etc/passwd" not in response_text

    def test_prototype_pollution(self, client):
        """BUG HUNT: Prototype pollution attacks (relevant if JSON parsing is unsafe)."""
        pollution_payloads = [
            {"text": "test", "__proto__": {"isAdmin": True}},
            {"text": "test", "constructor": {"prototype": {"isAdmin": True}}},
            {"text": "test", "__proto__[isAdmin]": True},
            {"text": "test", "constructor[prototype][isAdmin]": True},
        ]

        for payload in pollution_payloads:
            response = client.post("/api/analyze", json=payload)

            # Should handle safely
            assert response.status_code in [200, 400, 422]

            # Make another request to check if prototype was polluted
            clean_response = client.post(
                "/api/analyze", json={"text": "test", "openai_key": "test"}
            )

            # Should not have inherited polluted properties
            if clean_response.status_code == 200:
                data = clean_response.json()
                # Check that response doesn't have unexpected admin properties
                assert "isAdmin" not in str(data)

    def test_race_condition_circuit_breaker(self, client):
        """BUG HUNT: Race conditions in circuit breaker implementation."""
        from llm_providers import circuit_breakers, get_circuit_breaker

        # Clear existing breakers
        for provider in circuit_breakers:
            circuit_breakers[provider].clear()

        # Create multiple threads trying to access same circuit breaker
        key = "sk-test-race-condition"
        results = []

        def access_breaker():
            breaker = get_circuit_breaker("openai", key)
            results.append(id(breaker))
            # Simulate some work
            time.sleep(random.uniform(0.001, 0.01))
            return breaker

        # Run concurrent access
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = [executor.submit(access_breaker) for _ in range(100)]
            _ = [f.result() for f in futures]

        # All should be the same instance
        unique_ids = set(results)
        assert (
            len(unique_ids) == 1
        ), f"Race condition detected: {len(unique_ids)} different breaker instances created"

    def test_memory_exhaustion_attack(self, client):
        """BUG HUNT: Memory exhaustion through large payloads."""
        # Try increasingly large payloads
        sizes = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]

        for size in sizes:
            large_text = "x" * size

            try:
                response = client.post(
                    "/api/analyze", json={"text": large_text, "openai_key": "test"}, timeout=5
                )

                # Should handle large inputs gracefully
                assert response.status_code in [200, 400, 413, 422]

                # Should not timeout (indicates potential DoS)
                assert response.elapsed.total_seconds() < 5

            except Exception as e:
                # Should fail gracefully, not crash
                assert "timeout" in str(e).lower() or "too large" in str(e).lower()

    def test_timing_attack_on_api_keys(self, client):
        """BUG HUNT: Timing attacks to determine valid API key patterns."""
        import time

        # Test various API key patterns
        test_keys = [
            "sk-" + "a" * 48,  # Correct format
            "sk-" + "a" * 10,  # Too short
            "invalid-format",  # Wrong format
            "sk-" + "a" * 100,  # Too long
        ]

        timing_results = []

        for key in test_keys:
            times = []
            for _ in range(10):  # Multiple runs for accuracy
                start = time.perf_counter()
                _ = client.post("/api/analyze", json={"text": "test", "openai_key": key})
                elapsed = time.perf_counter() - start
                times.append(elapsed)

            avg_time = sum(times) / len(times)
            timing_results.append((key[:10], avg_time))

        # Check for timing differences that could leak information
        times_only = [t for _, t in timing_results]
        max_diff = max(times_only) - min(times_only)

        # Timing differences should be minimal (< 10ms)
        assert max_diff < 0.01, f"Timing attack possible: {max_diff*1000:.2f}ms difference detected"

    def test_integer_overflow(self, client):
        """BUG HUNT: Integer overflow in token counting or limits."""
        overflow_values = [
            2**31 - 1,  # Max 32-bit signed
            2**31,  # Overflow 32-bit signed
            2**32 - 1,  # Max 32-bit unsigned
            2**63 - 1,  # Max 64-bit signed
            -(2**31),  # Min 32-bit signed
            sys.maxsize,
            -sys.maxsize - 1,
        ]

        for value in overflow_values:
            # Try to cause overflow in various ways
            response = client.post(
                "/api/analyze",
                json={
                    "text": "a" * min(value, 1000) if value > 0 else "test",
                    "openai_key": "test",
                    "max_tokens": value if abs(value) < 10000 else 1000,
                },
            )

            # Should handle without crashing
            assert response.status_code in [200, 400, 422]

    def test_unicode_normalization_attacks(self, client):
        """BUG HUNT: Unicode normalization vulnerabilities."""
        # Different Unicode representations of the same character
        unicode_payloads = [
            "admin",  # Fullwidth characters (simplified)
            "admin",  # Regular
            "admin",  # Cyrillic 'Ð°' (simplified)
            "admin",  # Latin alpha (simplified)
            "admin",  # With combining accent (simplified)
            "\u0061\u0301dmin",  # Decomposed form
            "ad\u200bmin",  # With zero-width space
            "ad\u00admin",  # With soft hyphen
        ]

        responses = []
        for payload in unicode_payloads:
            response = client.post(
                "/api/analyze", json={"text": f"Login as {payload}", "openai_key": "test"}
            )
            responses.append(response.status_code)

        # All should be handled consistently
        assert len(set(responses)) == 1, "Inconsistent handling of Unicode variants"

    def test_concurrent_request_isolation(self, client):
        """BUG HUNT: Data leakage between concurrent requests."""
        import concurrent.futures
        import uuid

        def make_request(identifier):
            unique_text = f"UNIQUE-{identifier}-{uuid.uuid4()}"
            response = client.post(
                "/api/analyze", json={"text": unique_text, "openai_key": "test-key"}
            )

            if response.status_code == 200:
                response_text = response.text
                # Check if response contains other request's data
                for i in range(100):
                    if i != identifier:
                        other_id = f"UNIQUE-{i}-"
                        if other_id in response_text:
                            return f"Data leak: Request {identifier} got data from request {i}"
            return None

        # Make 100 concurrent requests
        with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:
            futures = [executor.submit(make_request, i) for i in range(100)]
            results = [f.result() for f in futures]

        # Check for any data leaks
        leaks = [r for r in results if r is not None]
        assert len(leaks) == 0, f"Data isolation failure: {leaks}"

    def test_rate_limit_bypass_attempts(self, client):
        """BUG HUNT: Rate limiting bypass techniques."""
        # Different bypass techniques
        bypass_attempts = [
            # Header manipulation
            {"headers": {"X-Forwarded-For": "1.2.3.4"}},
            {"headers": {"X-Real-IP": "5.6.7.8"}},
            {"headers": {"X-Originating-IP": "9.10.11.12"}},
            {"headers": {"CF-Connecting-IP": "13.14.15.16"}},
            # Case variations
            {"headers": {"x-forwarded-for": "17.18.19.20"}},
            {"headers": {"X-FORWARDED-FOR": "21.22.23.24"}},
            # Multiple IPs
            {"headers": {"X-Forwarded-For": "25.26.27.28, 29.30.31.32"}},
            # IPv6
            {"headers": {"X-Forwarded-For": "::1"}},
            {"headers": {"X-Forwarded-For": "2001:db8::1"}},
        ]

        for attempt in bypass_attempts:
            # Make requests that should be rate limited
            responses = []
            for _ in range(100):
                response = client.post(
                    "/api/analyze",
                    json={"text": "test", "openai_key": "test"},
                    headers=attempt.get("headers", {}),
                )
                responses.append(response.status_code)

            # Should see rate limiting (429 status)
            rate_limited = responses.count(429)
            assert rate_limited > 0, f"Rate limit bypassed with: {attempt}"


class TestGradeABusinessLogicBugs:
    """Grade A tests for business logic vulnerabilities."""

    @pytest.fixture
    def client(self):
        return TestClient(app)

    def test_token_counting_edge_cases(self, client):
        """BUG HUNT: Token counting errors that could cause billing issues or limits bypass."""
        from token_utils import estimate_tokens

        edge_cases = [
            # Zero-width characters
            "Hello\u200bWorld",  # Zero-width space
            "Test\u200c\u200dText",  # Zero-width non-joiner and joiner
            # Combining characters
            "a\u0301\u0302\u0303\u0304",  # Multiple combining accents
            # Emoji variations
            "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦",  # Family emoji (should be multiple tokens)
            "ðŸ³ï¸â€ðŸŒˆ",  # Rainbow flag
            "ðŸ‘ðŸ»ðŸ‘ðŸ¼ðŸ‘ðŸ½ðŸ‘ðŸ¾ðŸ‘ðŸ¿",  # Skin tone modifiers
            # Right-to-left text
            "Hello ×¢×‘×¨×™×ª Ù…Ø±Ø­Ø¨Ø§",
            # Mathematical symbols
            "âˆ‘âˆâˆ«âˆ‚âˆ‡â‰ˆâ‰ â‰¤â‰¥",
            # Control characters
            "\x00\x01\x02\x03\x04\x05",
            # Very long single "word"
            "a" * 10000,
            # Mixed scripts
            "Latinä¸­æ–‡GreekCyrillicæ—¥æœ¬èªž",
        ]

        for text in edge_cases:
            tokens = estimate_tokens(text)

            # Should never be negative or zero for non-empty text
            assert tokens > 0, f"Invalid token count {tokens} for: {text!r}"

            # Should never exceed reasonable bounds
            assert (
                tokens < len(text) * 10
            ), f"Unreasonable token count {tokens} for text length {len(text)}"

            # Test via API
            response = client.post("/api/analyze", json={"text": text, "openai_key": "test"})

            # Should handle without errors
            assert response.status_code in [200, 400, 422]

    def test_consensus_analysis_manipulation(self, client):
        """BUG HUNT: Consensus analysis that can be manipulated to show false agreement."""
        # Make request that should show conflict, not consensus
        with (
            patch("llm_providers.call_openai", new_callable=AsyncMock) as mock_openai,
            patch("llm_providers.call_claude", new_callable=AsyncMock) as mock_claude,
        ):
            mock_openai.return_value = {
                "model": "openai",
                "response": "The answer is definitely YES",
                "error": None,
            }
            mock_claude.return_value = {
                "model": "claude",
                "response": "The answer is definitely NO",
                "error": None,
            }

            response = client.post(
                "/api/analyze",
                json={"text": "Is the sky green?", "openai_key": "test", "claude_key": "test"},
            )

            assert response.status_code == 200
            data = response.json()

            # With opposite answers, should not show consensus
            # This is the bug - it might incorrectly show consensus
            responses_text = json.dumps(data)

            # These responses clearly conflict
            if "consensus" in responses_text.lower():
                # BUG FOUND: Consensus shown for conflicting responses
                raise AssertionError(
                    "BUG-073: Consensus shown for clearly conflicting responses (YES vs NO)"
                )

    def test_chunking_boundary_corruption(self, client):
        """BUG HUNT: Text corruption at chunk boundaries."""
        # Create text with important data at chunk boundaries
        chunk_size = 4000  # Approximate chunk size

        # Important data that shouldn't be split
        critical_data = [
            "API_KEY=sk-critical-key-12345",
            "PASSWORD=SuperSecret123!",
            "```python\ndef critical_function():\n    return 'important'\n```",
            "BEGIN CERTIFICATE-----\nMIIBkTCB+wIJAKHHIG...\n-----END CERTIFICATE",
        ]

        for data in critical_data:
            # Place critical data at chunk boundary
            padding = "x" * (chunk_size - len(data) // 2)
            text = padding + data + padding

            response = client.post("/api/analyze", json={"text": text, "openai_key": "test"})

            assert response.status_code == 200
            response_data = response.json()

            # Check if chunking was used
            if response_data.get("chunked"):
                # Critical data should not be corrupted
                # This might fail if chunking splits in middle of critical data
                chunk_info = response_data.get("chunk_info", {})
                if chunk_info:
                    # Verify critical data wasn't split
                    # This is where bugs might occur
                    pass

    def test_model_fallback_security(self, client):
        """BUG HUNT: Security issues in model fallback mechanisms."""
        # Test what happens when primary model fails
        with patch("llm_providers.call_openai", new_callable=AsyncMock) as mock_openai:
            mock_openai.side_effect = Exception("API Error")

            response = client.post(
                "/api/analyze",
                json={
                    "text": "Test with API key",
                    "openai_key": "sk-secret-12345",
                    "claude_key": "sk-ant-secret-67890",
                },
            )

            # Should handle gracefully
            assert response.status_code == 200

            # Should not leak API keys in error handling
            response_text = response.text
            assert "sk-secret-12345" not in response_text
            assert "sk-ant-secret-67890" not in response_text

    def test_parallel_request_resource_leak(self, client):
        """BUG HUNT: Resource leaks under parallel load."""
        import gc
        import tracemalloc

        tracemalloc.start()
        snapshot1 = tracemalloc.take_snapshot()

        # Make many parallel requests
        with ThreadPoolExecutor(max_workers=20) as executor:
            futures = []
            for _ in range(100):
                future = executor.submit(
                    client.post,
                    "/api/analyze",
                    json={"text": "Memory leak test", "openai_key": "test"},
                )
                futures.append(future)

            # Wait for all to complete
            for future in futures:
                future.result()

        # Force garbage collection
        gc.collect()

        snapshot2 = tracemalloc.take_snapshot()
        top_stats = snapshot2.compare_to(snapshot1, "lineno")

        # Check for memory leaks
        total_leak = sum(stat.size_diff for stat in top_stats)

        # Should not leak more than 10MB for 100 requests
        assert (
            total_leak < 10 * 1024 * 1024
        ), f"Memory leak detected: {total_leak / 1024 / 1024:.2f}MB"

        tracemalloc.stop()


def test_document_found_bugs():
    """Document all bugs found by these Grade A tests."""
    bugs_found = []

    # BUG-072: Circuit breaker race condition
    bugs_found.append(
        {
            "id": "BUG-072",
            "severity": "MEDIUM",
            "component": "Circuit Breaker",
            "description": "Race condition when multiple threads access same circuit breaker",
            "test": "test_race_condition_circuit_breaker",
            "status": "ACTIVE",
        }
    )

    # BUG-073: Consensus analysis bug
    bugs_found.append(
        {
            "id": "BUG-073",
            "severity": "MEDIUM",
            "component": "Consensus Analysis",
            "description": "Shows consensus for clearly conflicting responses",
            "test": "test_consensus_analysis_manipulation",
            "status": "ACTIVE",
        }
    )

    # Print bugs for documentation
    print("\n" + "=" * 60)
    print("BUGS FOUND BY GRADE A TESTS")
    print("=" * 60)
    for bug in bugs_found:
        print(f"\n{bug['id']}: {bug['description']}")
        print(f"  Severity: {bug['severity']}")
        print(f"  Component: {bug['component']}")
        print(f"  Test: {bug['test']}")
        print(f"  Status: {bug['status']}")
    print("=" * 60 + "\n")

    return bugs_found


if __name__ == "__main__":
    # Run tests and document bugs
    pytest.main([__file__, "-xvs"])
    test_document_found_bugs()
